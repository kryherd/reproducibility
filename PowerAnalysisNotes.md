# Power Analysis Notes

Out of 897 education research studies, sample sizes tended to be 25-30 subjects. Most studies were not able to detect a small difference, and one-third to one-half had the power to detect a large effect (Cook & Halata, 2015).

**References**:  
* Cook, D. A., & Hatala, R. (2015). Got power? A systematic review of sample size adequacy in health professions education research. Advances in Health Sciences Education : Theory and Practice, 20(1), 73–83. http://doi.org/10.1007/s10459-014-9509-5

## Linear mixed-effects models

Advantages of linear mixed-effects models  

* can model subjects and items in one model
* deals with missing-ness
* options for analyses of experimental and item differences

Random effects structures

* Barr et al. (2013): you should use the most complex random-effect structure that you can, as long as it converges.
* Bates et al. (2015): you should use parsimonious models that contain only components supported by the data

**References**:  

* Barr, D. J., Levy, R., Scheepers, C., & Tily, H. J. (2013). Random effects structure for confirmatory hypothesis testing: Keep it maximal. Journal of Memory and Language, 68(3), 255–278. http://doi.org/10.1016/j.jml.2012.11.001
* Bates, D., Kliegl, R., Vasishth, S., & Baayen, H. (2015). Parsimonious Mixed Models, 1–27. http://doi.org/arXiv:1506.04967
* Matuschek, H., Kliegl, R., Vasishth, S., Baayen, H., & Bates, D. (2017). Balancing Type I error and power in linear mixed models. Journal of Memory and Language, 94, 305–315. http://doi.org/10.1016/j.jml.2017.01.001

## Individual differences

Commonly use correlation coefficients (*r*) to show how associated two variables are.  

Cohen (1988) -- medium effects should be detectable by naked eye

* Small: .1
* Medium: .3
* Large: .5  

Hemphill (2003) -- based on thee actual correlation coefficients reported in a bunch of studies. But, lots of the coefficients were based on treatment/therapy experiments that used Cohen's *d* instead of Pearson *r* values.

* Small: <.2
* Medium: .2-.3
* Large: >.3  

Gignac & Szodorai (2016) -- 708 correlations from 24 meta-analyses

* Small: .1
* Medium: .2
* Large: .3

**References**:  

* Hemphill, J. F. (2003). Interpreting the magnitudes of correlation coefficients. American Psychologist, 58(1), 78–79. http://doi.org/10.1037/0003-066X.58.1.78
* Cohen, J. (1992). A power primer. Psychological Bulletin, 112(1), 155–159. http://doi.org/10.1037//0033-2909.112.1.155
* Gignac, G. E., & Szodorai, E. T. (2016). Effect size guidelines for individual differences researchers. Personality and Individual Differences, 102, 74–78. http://doi.org/10.1016/j.paid.2016.06.069

## Neuroimaging & sample size

* Minarik et al. (2016) found a significant effect with 75 subjects -- this effect was not present with 20-subject random samples of the dataset (only present in <20%) or even really with 60-subject samples (effect present in 51% of randomizations).
* Sideridis et al. (2014) tested SEM models of functional brain connectivity and found that 70-80 participants gave close fit, while 50 participants gave satisfactory fit. 40 or less was unacceptable.


**References**:  

* Minarik, T., Berger, B., Althaus, L., Bader, V., Biebl, B., Brotzeller, F., … Sauseng, P. (2016). The Importance of Sample Size for Reproducibility of tDCS Effects. Frontiers in Human Neuroscience, 10(September), 1–5. http://doi.org/10.3389/fnhum.2016.00453
* Sideridis, G., Simos, P., Papanicolaou, A., & Fletcher, J. (2014). Using Structural Equation Modeling to Assess Functional Connectivity in the Brain: Power and Sample Size Considerations. Educational and Psychological Measurement, 74(5), 733–758. http://doi.org/10.1177/0013164414525397


